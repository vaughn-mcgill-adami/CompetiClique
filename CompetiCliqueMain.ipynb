{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1718218169936,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"eo0Ii2Da3pG3"},"outputs":[{"name":"stdout","output_type":"stream","text":["running locally\n"]}],"source":["LOCAL = None\n","try:\n","\tfrom google import colab\n","\tLOCAL = False\n","except ImportError:\n","\tprint(\"running locally\")\n","\tLOCAL = True\n","\n","if not LOCAL:\n","\timport os\n","\tos.chdir(\"/content/drive/MyDrive/Colab Notebooks/CompetiClique\")"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":6866,"status":"ok","timestamp":1718218176799,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"Bl9sioCX3HcR"},"outputs":[],"source":["from competiclique_the_game import CompetiClique\n","from simple_decoder_transformer import SimpleDecoderTransformer\n","\n","from copy import deepcopy\n","\n","import torch\n","from torch.distributions.categorical import Categorical\n","\n","from collections import deque\n","\n","from tqdm import tqdm\n","\n","from config import *"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1718218176800,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"xQWdUmdaaOxp"},"outputs":[],"source":["def edge_condition(x : torch.Tensor):\n","  assert len(x) % 2 == 0\n","  adjacency_list = dict()\n","\n","  for k in range(len(x)//2):\n","    u = x[2*k].item()\n","    v = x[2*k+1].item()\n","\n","    if u == v:\n","      return False\n","    if len(adjacency_list) == 0:\n","      adjacency_list[u] = {v}\n","      adjacency_list[v] = {u}\n","    else:\n","      if u not in adjacency_list.keys() and v not in adjacency_list.keys():\n","        return False\n","      if u in adjacency_list.keys():\n","        if v in adjacency_list[u]:\n","          return False\n","      if v in adjacency_list.keys():\n","        if u in adjacency_list[v]:\n","          return False\n","    adjacency_list[u] = {v}\n","    adjacency_list[v] = {u}\n","  return True\n","\n","def get_forbidden_mask(size):\n","  assert size % 2 == 0\n","\n","  k = 0\n","  forbidden_mask = []\n","  while k < size//2:\n","    pair = torch.randint(low=AVAILABLE_TOKEN, high=FORBIDDEN_TOKEN+1, size=(2,)) # note these two tokens are consecutive.\n","    if pair[0].item() != FORBIDDEN_TOKEN or pair[1].item() != FORBIDDEN_TOKEN:\n","      k += 1\n","      forbidden_mask.append(pair)\n","  forbidden_mask = torch.cat(forbidden_mask, dim = 0)\n","  return forbidden_mask\n","\n","def generate_batch(batch_size : int, episode_length : int):\n","  \"\"\"\n","  generates data for a subproblem, namely listing edges in an order so that at least one vertex of each edge is already present in the graph.\n","  \"\"\"\n","\n","  batch = []\n","\n","  curr_episode = 0\n","  while curr_episode < batch_size:\n","    x = torch.randint(low=0,high=VERTEX_VOCABULARY,size=(2*episode_length,))\n","    if edge_condition(x):\n","      for end_observation_index in range(1,episode_length):\n","        forbidden_mask = get_forbidden_mask(size=2*end_observation_index)\n","        xp = torch.cat((\n","            torch.flatten(torch.stack((x[:2*end_observation_index],forbidden_mask), dim=0).transpose(-1,-2)),\n","            torch.tensor([END_OBSERVATION_TOKEN]),\n","            x[2*end_observation_index:]), dim=0)\n","        batch.append(xp)\n","      curr_episode += 1\n","  return torch.nested.nested_tensor(batch).to_padded_tensor(padding=PAD_TOKEN)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":5334,"status":"ok","timestamp":1718218182121,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"mw6bt4ruOk6c"},"outputs":[],"source":["embedding_dim = 64\n","mlp_dim = 96\n","\n","device = torch.device(\"cpu\")\n","\n","model = SimpleDecoderTransformer(L=2, H=4, d_e=embedding_dim, d_mlp = mlp_dim).to(device)\n","pre_training_optimizer = torch.optim.Adam(params = model.parameters(), lr = 0.001)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1718218182122,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"gglz9qL80lsC"},"outputs":[],"source":["batch_size = 1000\n","episode_length = 10"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":532},"collapsed":true,"executionInfo":{"elapsed":175407,"status":"error","timestamp":1718218357519,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"LTLuaQ72nlrF","outputId":"bd3ee047-aac5-4c92-ed5d-36157c0fc96f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/nested/__init__.py:166: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. (Triggered internally at ../aten/src/ATen/NestedTensorImpl.cpp:178.)\n","  return _nested.nested_tensor(\n"]},{"name":"stdout","output_type":"stream","text":["2.7211122512817383\n","2.6007883548736572\n","2.4864585399627686\n","2.372758150100708\n","2.2727277278900146\n","2.181589365005493\n","2.102168321609497\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-498ac63f62da>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_TOKENS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/Colab Notebooks/CompetiClique/simple_decoder_transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0;31m#       print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# multihead attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m                 \u001b[0;31m#       print(X.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1264\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1267\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5363\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is False but in_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5364\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5365\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5366\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is True but q_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4882\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4883\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4884\u001b[0;31m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4885\u001b[0m             \u001b[0;31m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4886\u001b[0m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["epochs = 100\n","\n","for epoch in range(epochs):\n","  batch = generate_batch(batch_size=batch_size, episode_length=episode_length).to(device)\n","\n","  Y = batch[:-1]\n","  X = batch[1:]\n","\n","  indices = torch.arange(N_TOKENS).to(device)[None, None, :] == Y[:, :, None]\n","  loss = -torch.mean(torch.log(model(X)[indices]))\n","\n","  loss.backward()\n","  pre_training_optimizer.step()\n","  pre_training_optimizer.zero_grad()\n","\n","  print(loss.item())"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":186,"status":"ok","timestamp":1718217655463,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"reoIqlToDq54"},"outputs":[],"source":["PATH = \"/content/drive/MyDrive/Colab Notebooks/CompetiClique/supervised_pretrained_model.pt\""]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":359,"status":"ok","timestamp":1718217657530,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"e6A1--5xCghB"},"outputs":[],"source":["torch.save({\n","            'epoch': epochs,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': pre_training_optimizer.state_dict()\n","            }, PATH)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":207,"status":"ok","timestamp":1718217662792,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"9Ndl0k0PDjxy","outputId":"3a3c356c-b13d-4f07-cfd9-743ea88fc83c"},"outputs":[{"data":{"text/plain":["SimpleDecoderTransformer(\n","  (vertex_embedding): Embedding(14, 64)\n","  (position_embedding): Embedding(90, 64)\n","  (trunk): ModuleList(\n","    (0-1): 2 x ModuleList(\n","      (0): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (1): MultiheadAttention(\n","        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n","      )\n","      (2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (3): Linear(in_features=64, out_features=96, bias=True)\n","      (4): GELU(approximate='none')\n","      (5): Linear(in_features=96, out_features=64, bias=True)\n","    )\n","  )\n","  (final_batch_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (final_linear): Linear(in_features=64, out_features=14, bias=True)\n",")"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(PATH)['model_state_dict'])\n","model.train()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62978,"status":"ok","timestamp":1718217991459,"user":{"displayName":"Vaughn Mcgill-Adami","userId":"09689378408207166504"},"user_tz":420},"id":"IDVAx853X54E","outputId":"60443a55-3322-41d8-8683-db688c4d9b6e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 5000/5000 [01:00<00:00, 83.07it/s] \n"]},{"name":"stdout","output_type":"stream","text":["batch 0: {'average_game_length': 1.025, 'max_game_length': 2, 'average_builder_return': -0.9750000238418579, 'average_forbidder_return': -1.0}\n"]}],"source":["eval_only = True\n","\n","num_batches = 1\n","batch_size = 5000\n","lr = 0.05\n","discount_factor = 0.9\n","\n","game = CompetiClique(clique_size = 3,\n","\t\t\t\t\t\t\tedges_per_builder_turn=2,\n","\t\t\t\t\t\tvertices_per_forbidder_turn=2\n","\t\t\t\t\t\t)\n","\n","\"\"\"\n","Vanilla policy gradient implementation.\n","\"\"\"\n","builder_policy = deepcopy(model).to(device)#SimpleDecoderTransformer(L = 2, H = 4, d_e = 32, d_mlp = 48)\n","forbidder_policy = deepcopy(model).to(device)#SimpleDecoderTransformer(L = 2, H = 4, d_e = 32, d_mlp = 48)\n","\n","builder_optimizer = torch.optim.Adam(builder_policy.parameters(), lr=lr)\n","forbidder_optimizer = torch.optim.Adam(forbidder_policy.parameters(), lr=lr)\n","\n","builder_policy.train()\n","forbidder_policy.train()\n","\n","for batch in range(num_batches):\n","\t#batch_builder_observations = deque()\n","\tbatch_builder_actions = deque()\n","\tbatch_builder_returns = deque()\n","\n","\t#batch_forbidder_observations = deque()\n","\tbatch_forbidder_actions = deque()\n","\tbatch_forbidder_returns = deque()\n","\n","\tbatch_stats = {'average_game_length' : deque(),\n","\t\t\t\t\t\t'max_game_length' : 0}\n","\n","\tfor episode in tqdm(range(batch_size)):\n","\t\t#builder_observations = deque()\n","\t\tbuilder_actions_probs = deque()\n","\t\tbuilder_actions_chosen = deque()\n","\t\tbuilder_rewards = deque()\n","\t\t#forbidder_observations = deque()\n","\t\tforbidder_actions_probs = deque()\n","\t\tforbidder_actions_chosen = deque()\n","\t\tforbidder_rewards = deque()\n","\n","\t\tobservation = game.reset()\n","\t\tturn_number = 0\n","\n","\t\tprevobs = None\n","\n","\t\twhile observation is not None:\n","\t\t\t#prevobs = observation\n","\t\t\tif turn_number % 2 == 0:\n","\t\t\t\t#builder_observations.append(observation)\n","\n","\t\t\t\tformatted_action_probs = []\n","\t\t\t\tformatted_action_chosen = []\n","\t\t\t\tfor k in range(2*game.M):\n","\t\t\t\t\tobservation = observation.to(device)\n","\t\t\t\t\taction_probs = builder_policy(observation)[0][-1]\n","\t\t\t\t\taction_chosen = Categorical(probs = action_probs).sample()\n","\t\t\t\t\tformatted_action_probs.append(action_probs)\n","\t\t\t\t\tformatted_action_chosen.append(action_chosen)\n","\t\t\t\t\tobservation = torch.cat((observation,torch.unsqueeze(torch.unsqueeze(action_chosen,dim=0),dim=0)), dim=1)\n","\t\t\t\tformatted_action_probs = torch.stack(formatted_action_probs, dim=0)\n","\t\t\t\tformatted_action_chosen = torch.stack(formatted_action_chosen, dim=0)\n","\n","\t\t\t\t#print(\"before\\n\", observation)\n","\n","\t\t\t\tobservation, reward = game.step(formatted_action_chosen, 'builder')\n","\n","\t\t\t\t#print(\"after\\n\", observation)\n","\n","\t\t\t\tbuilder_actions_probs.append(formatted_action_probs)\n","\t\t\t\tbuilder_actions_chosen.append(formatted_action_chosen)\n","\t\t\t\tbuilder_rewards.append(reward)\n","\t\t\telse:\n","\t\t\t\t#forbidder_observations.append(observation)\n","\n","\t\t\t\tformatted_action_probs = []\n","\t\t\t\tformatted_action_chosen = []\n","\t\t\t\tfor k in range(game.N):\n","\t\t\t\t\tobservation = observation.to(device)\n","\t\t\t\t\taction_probs = forbidder_policy(observation)[0][-1]\n","\t\t\t\t\taction_chosen = Categorical(probs = action_probs).sample()\n","\t\t\t\t\tformatted_action_probs.append(action_probs)\n","\t\t\t\t\tformatted_action_chosen.append(action_chosen)\n","\t\t\t\t\tobservation = torch.cat((observation,torch.unsqueeze(torch.unsqueeze(action_chosen,dim=0),dim=0)), dim=1)\n","\t\t\t\tformatted_action_probs = torch.stack(formatted_action_probs, dim=0)\n","\t\t\t\tformatted_action_chosen = torch.stack(formatted_action_chosen, dim=0)\n","\n","\t\t\t\tobservation, reward = game.step(formatted_action_chosen, 'forbidder')\n","\n","\t\t\t\tforbidder_actions_probs.append(formatted_action_probs)\n","\t\t\t\tforbidder_actions_chosen.append(formatted_action_chosen)\n","\t\t\t\tforbidder_rewards.append(reward)\n","\t\t\tturn_number += 1\n","\n","\t\t#print(f\"previous observation on turn {turn_number}:\", prevobs)\n","\t\t#print(f\"previous action on turn {turn_number}\", builder_actions_chosen[-1] if turn_number%2==1 else forbidder_actions_chosen[-1] if len(forbidder_actions_chosen)!=0 else \"empty\")\n","\n","\t\tbatch_stats['average_game_length'].append(turn_number)\n","\t\tbatch_stats['max_game_length'] = max(batch_stats['max_game_length'], turn_number)\n","\n","\t\tif len(builder_rewards) != 0:\n","\t\t\tbuilder_rewards = torch.tensor(list(builder_rewards))\n","\n","\t\t\t#print(\"builder_rewards:\", builder_rewards)\n","\n","\t\t\tbuilder_discounted_returns = torch.tensor([sum(discount_factor**i*reward for i, reward in enumerate(builder_rewards[k:])) for k in range(len(builder_rewards))])\n","\t\t\tbuilder_discounted_returns = builder_discounted_returns.repeat_interleave(2*game.M)\n","\n","\t\t\tbuilder_actions_probs = torch.cat(list(builder_actions_probs))\n","\t\t\tbuilder_actions_chosen = torch.cat(list(builder_actions_chosen))\n","\n","\t\t\tbuilder_actions = builder_actions_probs[torch.arange(len(builder_actions_probs)), builder_actions_chosen]\n","\n","\t\t\t#print(\"builder_discounted_returns:\", builder_discounted_returns)\n","\n","\t\t\tbatch_builder_actions.append(builder_actions)\n","\t\t\tbatch_builder_returns.append(builder_discounted_returns)\n","\n","\n","\t\tif len(forbidder_rewards) != 0:\n","\t\t\tforbidder_rewards = torch.tensor(list(forbidder_rewards))\n","\n","\t\t\t#print(\"forbidder_rewards:\", forbidder_rewards)\n","\n","\t\t\tforbidder_discounted_returns = torch.tensor([sum(discount_factor**i*reward for i, reward in enumerate(forbidder_rewards[k:])) for k in range(len(forbidder_rewards))])\n","\t\t\tforbidder_discounted_returns = forbidder_discounted_returns.repeat_interleave(game.N)\n","\n","\t\t\tforbidder_actions_probs = torch.cat(list(forbidder_actions_probs))\n","\t\t\tforbidder_actions_chosen = torch.cat(list(forbidder_actions_chosen))\n","\n","\t\t\tforbidder_actions = forbidder_actions_probs[torch.arange(len(forbidder_actions_probs)), forbidder_actions_chosen]\n","\n","\t\t\tbatch_forbidder_actions.append(forbidder_actions)\n","\t\t\tbatch_forbidder_returns.append(forbidder_discounted_returns)\n","\n","\t\t\t#print(\"forbidder_discounted_returns:\", forbidder_discounted_returns)\n","\t\t\t#print(\"forbidden_token = \", FORBIDDEN_TOKEN)\n","\t\t\t#print(\"available_token = \", AVAILABLE_TOKEN)\n","\t\t\t#return\n","\n","\tbatch_stats['average_game_length'] = sum(batch_stats['average_game_length'])/len(batch_stats['average_game_length'])\n","\n","\tif len(batch_builder_actions) != 0:\n","\t\tbatch_builder_actions = torch.stack(list(batch_builder_actions), dim=0)\n","\t\tbatch_builder_returns = torch.stack(list(batch_builder_returns), dim=0).to(device)\n","\n","\t\tif not eval_only:\n","\t\t\tbuilder_loss = -torch.mean((torch.log(batch_builder_actions)*batch_builder_returns).sum(dim=-1))\n","\n","\t\t\tbuilder_loss.backward()\n","\t\t\tbuilder_optimizer.step()\n","\t\t\tbuilder_optimizer.zero_grad()\n","\n","\t\t\tbatch_stats['builder_loss'] = builder_loss.cpu().item()\n","\t\tbatch_stats['average_builder_return'] = torch.mean(batch_builder_returns[:,0]).cpu().item()\n","\tif len(batch_forbidder_actions) != 0:\n","\t\tbatch_forbidder_actions = torch.stack(list(batch_forbidder_actions), dim=0)\n","\t\tbatch_forbidder_returns = torch.stack(list(batch_forbidder_returns), dim=0).to(device)\n","\n","\t\tif not eval_only:\n","\t\t\tforbidder_loss = -torch.mean((torch.log(batch_forbidder_actions)*batch_forbidder_returns).sum(dim=-1))\n","\n","\t\t\tforbidder_loss.backward()\n","\t\t\tforbidder_optimizer.step()\n","\t\t\tforbidder_optimizer.zero_grad()\n","\n","\t\t\tbatch_stats['forbidder_loss'] = forbidder_loss.cpu().item()\n","\t\t#print(\"builder ret\\n\", batch_builder_returns)\n","\t\t#print(\"forbidder ret\\n\", batch_forbidder_returns)\n","\t\tbatch_stats['average_forbidder_return'] = torch.mean(batch_forbidder_returns[:,0]).cpu().item()\n","\tprint(f\"batch {batch}:\", batch_stats)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOieFBrnbK909V9Zvx8pt1W","gpuType":"T4","mount_file_id":"1Et6rrl1QX76NCW8eVa504ypPB8xX67J1","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}
